{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "import pickle\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_df=pd.read_csv(\"./raw_data/train_preliminary/click_log.csv\")\n",
    "ad_df=pd.read_csv(\"./raw_data/train_preliminary/ad.csv\")\n",
    "train_user=pd.read_csv(\"./raw_data/train_preliminary/user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>click_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>30920</td>\n",
       "      <td>567330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>30920</td>\n",
       "      <td>3072255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>30920</td>\n",
       "      <td>2361327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>309204</td>\n",
       "      <td>325532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>309204</td>\n",
       "      <td>2746730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>309204</td>\n",
       "      <td>726402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79</td>\n",
       "      <td>309204</td>\n",
       "      <td>2851451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>309204</td>\n",
       "      <td>1569716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>309204</td>\n",
       "      <td>71956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>309204</td>\n",
       "      <td>322354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  user_id  creative_id  click_times\n",
       "0     9    30920       567330            1\n",
       "1    65    30920      3072255            1\n",
       "2    56    30920      2361327            1\n",
       "3     6   309204       325532            1\n",
       "4    59   309204      2746730            1\n",
       "5    12   309204       726402            1\n",
       "6    79   309204      2851451            1\n",
       "7    32   309204      1569716            1\n",
       "8     5   309204        71956            1\n",
       "9     8   309204       322354            1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creative_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>381</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>148</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>713</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>695</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>765</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>34647</td>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creative_id  ad_id product_id  product_category  advertiser_id industry\n",
       "0            1      1         \\N                 5            381       78\n",
       "1            4      4         \\N                 5            108      202\n",
       "2            7      7         \\N                 5            148      297\n",
       "3            8      8         \\N                 5            713      213\n",
       "4            9      9         \\N                 5            695      213\n",
       "5           10     10         \\N                 5            100       73\n",
       "6           12     12         \\N                 5            765        6\n",
       "7           13     13         \\N                 5            113      267\n",
       "8           16     16         \\N                 5            623        1\n",
       "9           20     20      34647                 5            312      267"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age  gender\n",
       "0        1    4       1\n",
       "1        2   10       1\n",
       "2        3    7       2\n",
       "3        4    5       1\n",
       "4        5    4       1\n",
       "5        6    6       1\n",
       "6        7    6       2\n",
       "7        8    5       1\n",
       "8        9    5       1\n",
       "9       10    9       2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files():\n",
    "    #合并点击记录\n",
    "    print(\"merge click files...\")\n",
    "    click_df=pd.read_csv(\"./raw_data/train_preliminary/click_log.csv\")\n",
    "    train_click=pd.read_csv(\"./raw_data/train_semi_final/click_log.csv\")\n",
    "    train_click=train_click[train_click.user_id>2000000]\n",
    "    click_df=click_df.append(train_click)\n",
    "    click_df=click_df.sort_values(by=[\"time\"]).drop_duplicates()   \n",
    "    \n",
    "    #合并广告信息\n",
    "    print(\"merge ad files...\")\n",
    "    ad_df=pd.read_csv(\"./raw_data/train_preliminary/ad.csv\")\n",
    "    ad_df=ad_df.append(pd.read_csv(\"./raw_data/train_semi_final/ad.csv\"))\n",
    "    ad_df=ad_df.drop_duplicates() \n",
    "    \n",
    "    #合并用户信息\n",
    "    print(\"merge user files...\")\n",
    "    train_user=pd.read_csv(\"./raw_data/train_preliminary/user.csv\")\n",
    "    train_user=train_user.reset_index(drop=True)\n",
    "    train_user['age']=train_user['age']-1\n",
    "    train_user['gender']=train_user['gender']-1\n",
    "    test_user=pd.read_csv(\"./raw_data/train_semi_final/user.csv\")[-1000000:].drop_duplicates('user_id')[['user_id']].reset_index(drop=True)\n",
    "    test_user=test_user.sort_values(by='user_id').reset_index(drop=True)\n",
    "    test_user['age']=-1\n",
    "    test_user['gender']=-1\n",
    "\n",
    "    #合并点击，广告，用户信息\n",
    "    print(\"merge all files...\")\n",
    "    click_df=click_df.merge(ad_df,on=\"creative_id\",how='left')\n",
    "    click_df=click_df.merge(train_user,on=\"user_id\",how='left')\n",
    "    click_df=click_df.fillna(-1)\n",
    "    click_df=click_df.replace(\"\\\\N\",-1)\n",
    "    for f in click_df:\n",
    "        click_df[f]=click_df[f].astype(int)\n",
    "    for i in range(10):\n",
    "        click_df['age_{}'.format(i)]=(click_df['age']==i).astype(np.int16) \n",
    "    for i in range(2):\n",
    "        click_df['gender_{}'.format(i)]=(click_df['gender']==i).astype(np.int16) \n",
    "    \n",
    "    \n",
    "    return click_df,train_user,test_user\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    click_df,train_user,test_user=merge_files() \n",
    "    #保存预处理文件\n",
    "    print(\"preprocess done! saving data...\")\n",
    "    click_df.to_pickle(\"./tmp_data/click.pkl\")\n",
    "    train_user.to_pickle(\"./tmp_data/train_user.pkl\")\n",
    "    test_user.to_pickle(\"./tmp_data/test_user.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Kflod sequence feature...\n",
      "Extract features done! saving data...\n"
     ]
    }
   ],
   "source": [
    "def get_agg_features(dfs,f1,f2,agg,log):    \n",
    "    #判定特殊情况\n",
    "    if type(f1)==str:\n",
    "        f1=[f1]\n",
    "    if agg!='size':\n",
    "        data=log[f1+[f2]]\n",
    "    else:\n",
    "        data=log[f1] \n",
    "    f_name='_'.join(f1)+\"_\"+f2+\"_\"+agg     \n",
    "    #聚合操作    \n",
    "    if agg==\"size\":\n",
    "        tmp = pd.DataFrame(data.groupby(f1).size()).reset_index()\n",
    "    elif agg==\"count\":\n",
    "        tmp = pd.DataFrame(data.groupby(f1)[f2].count()).reset_index()\n",
    "    elif agg==\"mean\":\n",
    "        tmp = pd.DataFrame(data.groupby(f1)[f2].mean()).reset_index()\n",
    "    elif agg==\"unique\":\n",
    "        tmp = pd.DataFrame(data.groupby(f1)[f2].nunique()).reset_index()\n",
    "    elif agg==\"max\":\n",
    "        tmp = pd.DataFrame(data.groupby(f1)[f2].max()).reset_index()\n",
    "    elif agg==\"min\":\n",
    "        tmp = pd.DataFrame(data.groupby(f1)[f2].min()).reset_index()\n",
    "    elif agg==\"sum\":\n",
    "        tmp = pd.DataFrame(data.groupby(f1)[f2].sum()).reset_index()\n",
    "    elif agg==\"std\":\n",
    "        tmp = pd.DataFrame(data.groupby(f1)[f2].std()).reset_index()\n",
    "    elif agg==\"median\":\n",
    "        tmp = pd.DataFrame(data.groupby(f1)[f2].median()).reset_index()\n",
    "    else:\n",
    "        raise \"agg error\"   \n",
    "    #赋值聚合特征\n",
    "    for df in dfs:\n",
    "        try:\n",
    "            del df[f_name]\n",
    "        except:\n",
    "            pass\n",
    "        tmp.columns = f1+[f_name]\n",
    "        df[f_name]=df.merge(tmp, on=f1, how='left')[f_name] \n",
    "    del tmp\n",
    "    del data\n",
    "    gc.collect()\n",
    "    return [f_name]\n",
    "\n",
    "\n",
    "def sequence_text(dfs,f1,f2,log):\n",
    "    f_name='sequence_text_'+f1+'_'+f2\n",
    "    print(f_name)\n",
    "    #遍历log，获得用户的点击序列\n",
    "    dic,items={},[]\n",
    "    for item in log[[f1,f2]].values:\n",
    "        try:\n",
    "            dic[item[0]].append(str(item[1]))\n",
    "        except:\n",
    "            dic[item[0]]=[str(item[1])]      \n",
    "    for key in dic:\n",
    "        items.append([key,' '.join(dic[key])])\n",
    "    #赋值序列特征\n",
    "    temp=pd.DataFrame(items)\n",
    "    temp.columns=[f1,f_name]\n",
    "    temp = temp.drop_duplicates(f1)\n",
    "    for df in dfs:\n",
    "        try:\n",
    "            del df[f_name]\n",
    "        except:\n",
    "            pass\n",
    "        temp.columns = [f1]+[f_name]\n",
    "        df[f_name]=df.merge(temp, on=f1, how='left')[f_name]\n",
    "    gc.collect() \n",
    "    del temp\n",
    "    del items\n",
    "    del dic\n",
    "    return [f_name]\n",
    "\n",
    "def kfold(train_df,test_df,log_data,pivot):\n",
    "    #先对log做kflod统计，统计每条记录中pivot特征的性别年龄分布\n",
    "    kfold_features=['age_{}'.format(i) for i in range(10)]+['gender_{}'.format(i) for i in range(2)]\n",
    "    log=log_data[kfold_features+['user_id',pivot,'fold']]\n",
    "    tmps=[]\n",
    "    for fold in range(6):\n",
    "        tmp = pd.DataFrame(log[(log['fold'] != fold) & (log['fold'] != 5)].groupby(pivot)[kfold_features].mean()).reset_index()\n",
    "        tmp.columns=[pivot]+kfold_features\n",
    "        tmp['fold']=fold\n",
    "        tmps.append(tmp)\n",
    "    tmp=pd.concat(tmps,axis=0).reset_index()\n",
    "    tmp=log[['user_id',pivot,'fold']].merge(tmp,on=[pivot,'fold'],how='left')\n",
    "    del log\n",
    "    del tmps\n",
    "    gc.collect() \n",
    "    #获得用户点击的所有记录的平均性别年龄分布\n",
    "    tmp_mean = pd.DataFrame(tmp.groupby('user_id')[kfold_features].mean()).reset_index()\n",
    "    tmp_mean.columns=['user_id']+[f+'_'+pivot+'_mean' for f in kfold_features]\n",
    "    for df in [train_df,test_df]:\n",
    "        temp=df.merge(tmp_mean,on='user_id',how='left')\n",
    "        temp=temp.fillna(-1)\n",
    "        for f1 in [f+'_'+pivot+'_mean' for f in kfold_features]:\n",
    "            df[f1]=temp[f1]\n",
    "        del temp\n",
    "        gc.collect()\n",
    "    del tmp\n",
    "    del tmp_mean\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "def kfold_sequence(train_df,test_df,log_data,pivot): \n",
    "    #先对log做kflod统计，统计每条记录中pivot特征的性别年龄分布\n",
    "    kfold_features=['age_{}'.format(i) for i in range(10)]+['gender_{}'.format(i) for i in range(2)]\n",
    "    log=log_data[kfold_features+[pivot,'fold','user_id']]\n",
    "    tmps=[]\n",
    "    for fold in range(6):\n",
    "        tmp = pd.DataFrame(log[(log['fold'] != fold) & (log['fold'] != 5)].groupby(pivot)[kfold_features].mean()).reset_index()\n",
    "        tmp.columns=[pivot]+kfold_features\n",
    "        tmp['fold']=fold\n",
    "        tmps.append(tmp)\n",
    "    tmp=pd.concat(tmps,axis=0).reset_index()\n",
    "    tmp=log[[pivot,'fold','user_id']].merge(tmp,on=[pivot,'fold'],how='left')\n",
    "    tmp=tmp.fillna(-1)   \n",
    "    tmp[pivot+'_fold']=tmp[pivot]*10+tmp['fold']   \n",
    "    del log\n",
    "    del tmps\n",
    "    gc.collect() \n",
    "    #获得用户点击记录的年龄性别分布序列\n",
    "    tmp[pivot+'_fold']=tmp[pivot+'_fold'].astype(int)\n",
    "    kfold_sequence_features=sequence_text([train_df,test_df],'user_id',pivot+'_fold',tmp)\n",
    "    tmp=tmp.drop_duplicates([pivot+'_fold']).reset_index(drop=True)\n",
    "    #对每条记录年龄性别分布进行标准化\n",
    "    kfold_features=['age_{}'.format(i) for i in range(10)]+['gender_{}'.format(i) for i in range(2)]\n",
    "    ss=StandardScaler()\n",
    "    ss.fit(tmp[kfold_features])\n",
    "    tmp[kfold_features]=ss.transform(tmp[kfold_features])\n",
    "    for f in kfold_features:\n",
    "        tmp[f]=tmp[f].apply(lambda x:round(x,4))   \n",
    "#     #将每条记录年龄性别分布转成w2v形式的文件\n",
    "#     with open('data/sequence_text_user_id_'+pivot+'_fold'+\".{}d\".format(12),'w') as f:\n",
    "#         f.write(str(len(tmp))+' '+'12'+'\\n')\n",
    "#         for item in tmp[[pivot+'_fold']+kfold_features].values:\n",
    "#             f.write(' '.join([str(int(item[0]))]+[str(x) for x in item[1:]])+'\\n') \n",
    "#     tmp=gensim.models.KeyedVectors.load_word2vec_format('data/sequence_text_user_id_'+pivot+'_fold'+\".{}d\".format(12),binary=False)\n",
    "#     pickle.dump(tmp,open('data/sequence_text_user_id_'+pivot+'_fold'+\".{}d\".format(12),'wb'))\n",
    "#     del tmp\n",
    "#     gc.collect()  \n",
    "    return kfold_sequence_features\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #读取数据\n",
    "    click_log=pd.read_pickle('./tmp_data/click.pkl')\n",
    "    train_df=pd.read_pickle('./tmp_data/train_user.pkl')\n",
    "    test_df=pd.read_pickle('./tmp_data/test_user.pkl')\n",
    "    print(click_log.shape,train_df.shape,test_df.shape)\n",
    "    ################################################################################\n",
    "    #获取聚合特征\n",
    "    print(\"Extracting aggregate feature...\")\n",
    "    agg_features=[]\n",
    "    agg_features+=get_agg_features([train_df,test_df],'user_id','','size',click_log)\n",
    "    agg_features+=get_agg_features([train_df,test_df],'user_id','ad_id','unique',click_log)\n",
    "    agg_features+=get_agg_features([train_df,test_df],'user_id','creative_id','unique',click_log)\n",
    "    agg_features+=get_agg_features([train_df,test_df],'user_id','advertiser_id','unique',click_log)\n",
    "    agg_features+=get_agg_features([train_df,test_df],'user_id','industry','unique',click_log)\n",
    "    agg_features+=get_agg_features([train_df,test_df],'user_id','product_id','unique',click_log)\n",
    "    agg_features+=get_agg_features([train_df,test_df],'user_id','time','unique',click_log)\n",
    "    agg_features+=get_agg_features([train_df,test_df],'user_id','click_times','sum',click_log)\n",
    "    agg_features+=get_agg_features([train_df,test_df],'user_id','click_times','mean',click_log)\n",
    "    agg_features+=get_agg_features([train_df,test_df],'user_id','click_times','std',click_log)\n",
    "    train_df[agg_features]=train_df[agg_features].fillna(-1)\n",
    "    test_df[agg_features]=test_df[agg_features].fillna(-1)\n",
    "    print(\"Extracting aggregate feature done!\")\n",
    "    print(\"List aggregate feature names:\")\n",
    "    print(agg_features)\n",
    "    ################################################################################\n",
    "    #获取序列特征，用户点击的id序列\n",
    "    print(\"Extracting sequence feature...\")\n",
    "    text_features=[]\n",
    "    text_features+=sequence_text([train_df,test_df],'user_id','ad_id',click_log)\n",
    "    text_features+=sequence_text([train_df,test_df],'user_id','creative_id',click_log)\n",
    "    text_features+=sequence_text([train_df,test_df],'user_id','advertiser_id',click_log)\n",
    "    text_features+=sequence_text([train_df,test_df],'user_id','product_id',click_log)\n",
    "    text_features+=sequence_text([train_df,test_df],'user_id','industry',click_log)\n",
    "    text_features+=sequence_text([train_df,test_df],'user_id','product_category',click_log)\n",
    "    text_features+=sequence_text([train_df,test_df],'user_id','time',click_log)\n",
    "    text_features+=sequence_text([train_df,test_df],'user_id','click_times',click_log)\n",
    "    print(\"Extracting sequence feature done!\")\n",
    "    print(\"List sequence feature names:\")   \n",
    "    print(text_features)\n",
    "    ################################################################################\n",
    "    #获取K折统计特征，求出用户点击的所有记录的年龄性别平均分布\n",
    "    #赋值index,训练集为0-4，测试集为5\n",
    "    print(\"Extracting Kflod feature...\")\n",
    "    log=click_log.drop_duplicates(['user_id','creative_id']).reset_index(drop=True)\n",
    "    del click_log\n",
    "    gc.collect()\n",
    "    log['cont']=1\n",
    "    train_df['fold']=train_df.index%5\n",
    "    test_df['fold']=5\n",
    "    df=train_df.append(test_df)[['user_id','fold']].reset_index(drop=True)\n",
    "    log=log.merge(df,on='user_id',how='left')\n",
    "    del df\n",
    "    gc.collect()\n",
    "    #获取用户点击某特征的年龄性别平均分布\n",
    "    for pivot in ['creative_id','ad_id','product_id','advertiser_id','industry']:\n",
    "        print(\"Kfold\",pivot)\n",
    "        kfold(train_df,test_df,log,pivot)\n",
    "    del log\n",
    "    gc.collect()       \n",
    "    print(\"Extracting Kflod feature done!\")\n",
    "    ################################################################################\n",
    "    #获取K折序列特征,求出用户点击的每一条记录的年龄性别分布\n",
    "    #赋值index,训练集为0-4，测试集为5\n",
    "    print(\"Extracting Kflod sequence feature...\")\n",
    "    click_log=pd.read_pickle('./tmp_data/click.pkl')\n",
    "    log=click_log.reset_index(drop=True)\n",
    "    del click_log\n",
    "    gc.collect()\n",
    "    log['cont']=1\n",
    "    train_df['fold']=train_df.index%5\n",
    "    train_df['fold']=train_df['fold'].astype(int)\n",
    "    test_df['fold']=5\n",
    "    df=train_df.append(test_df)[['user_id','fold']].reset_index(drop=True)\n",
    "    log=log.merge(df,on='user_id',how='left')\n",
    "#     #获取用户点击某特征的年龄性别分布序列\n",
    "#     kfold_sequence_features=[] \n",
    "#     for pivot in ['creative_id','ad_id','product_id','advertiser_id','industry']:\n",
    "#         print(\"Kfold sequence\",pivot)\n",
    "#         kfold_sequence_features+=kfold_sequence(train_df,test_df,log,pivot) \n",
    "    del log\n",
    "#     gc.collect()        \n",
    "#     print(\"Extracting Kfold sequence feature done!\")\n",
    "#     print(\"List Kfold sequence feature names:\")   \n",
    "#     print(kfold_sequence_features)  \n",
    "    ################################################################################\n",
    "    print(\"Extract features done! saving data...\")\n",
    "    train_df.to_pickle('./tmp_data/train_df.pkl')\n",
    "    test_df.to_pickle('./tmp_data/test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_pickle('./tmp_data/train_df.pkl')\n",
    "test_df=pd.read_pickle('./tmp_data/test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_list=train_df.sequence_text_user_id_creative_id.tolist()+test_df.sequence_text_user_id_creative_id.tolist()\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "cntv = CountVectorizer(min_df=30)\n",
    "cntv_user = cntv.fit_transform(behavior_list)\n",
    "\n",
    "tfv = TfidfVectorizer(min_df=30,max_features=100000)\n",
    "tfv_user = tfv.fit_transform(behavior_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_list_ad=train_df.sequence_text_user_id_advertiser_id.tolist()+test_df.sequence_text_user_id_advertiser_id.tolist()\n",
    "cntv = CountVectorizer()\n",
    "cntv_user_ad = cntv.fit_transform(behavior_list_ad)\n",
    "\n",
    "tfv = TfidfVectorizer()\n",
    "tfv_user_ad = tfv.fit_transform(behavior_list_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['user_id__size', 'user_id_ad_id_unique',\n",
    "       'user_id_creative_id_unique', 'user_id_advertiser_id_unique',\n",
    "       'user_id_industry_unique', 'user_id_product_id_unique',\n",
    "       'user_id_time_unique', 'user_id_click_times_sum',\n",
    "       'user_id_click_times_mean', 'user_id_click_times_std',\n",
    "       'age_0_creative_id_mean',\n",
    "       'age_1_creative_id_mean', 'age_2_creative_id_mean',\n",
    "       'age_3_creative_id_mean', 'age_4_creative_id_mean',\n",
    "       'age_5_creative_id_mean', 'age_6_creative_id_mean',\n",
    "       'age_7_creative_id_mean', 'age_8_creative_id_mean',\n",
    "       'age_9_creative_id_mean', 'gender_0_creative_id_mean',\n",
    "       'gender_1_creative_id_mean', 'age_0_ad_id_mean', 'age_1_ad_id_mean',\n",
    "       'age_2_ad_id_mean', 'age_3_ad_id_mean', 'age_4_ad_id_mean',\n",
    "       'age_5_ad_id_mean', 'age_6_ad_id_mean', 'age_7_ad_id_mean',\n",
    "       'age_8_ad_id_mean', 'age_9_ad_id_mean', 'gender_0_ad_id_mean',\n",
    "       'gender_1_ad_id_mean', 'age_0_product_id_mean', 'age_1_product_id_mean',\n",
    "       'age_2_product_id_mean', 'age_3_product_id_mean',\n",
    "       'age_4_product_id_mean', 'age_5_product_id_mean',\n",
    "       'age_6_product_id_mean', 'age_7_product_id_mean',\n",
    "       'age_8_product_id_mean', 'age_9_product_id_mean',\n",
    "       'gender_0_product_id_mean', 'gender_1_product_id_mean',\n",
    "       'age_0_advertiser_id_mean', 'age_1_advertiser_id_mean',\n",
    "       'age_2_advertiser_id_mean', 'age_3_advertiser_id_mean',\n",
    "       'age_4_advertiser_id_mean', 'age_5_advertiser_id_mean',\n",
    "       'age_6_advertiser_id_mean', 'age_7_advertiser_id_mean',\n",
    "       'age_8_advertiser_id_mean', 'age_9_advertiser_id_mean',\n",
    "       'gender_0_advertiser_id_mean', 'gender_1_advertiser_id_mean',\n",
    "       'age_0_industry_mean', 'age_1_industry_mean', 'age_2_industry_mean',\n",
    "       'age_3_industry_mean', 'age_4_industry_mean', 'age_5_industry_mean',\n",
    "       'age_6_industry_mean', 'age_7_industry_mean', 'age_8_industry_mean',\n",
    "       'age_9_industry_mean', 'gender_0_industry_mean',\n",
    "       'gender_1_industry_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "train_csr = sparse.csr_matrix(train_df[features])\n",
    "test_csr = sparse.csr_matrix(test_df[features])\n",
    "# CountVectorizer结果合并\n",
    "train_csr = sparse.hstack((train_csr, cntv_user[:900000])).tocsr()\n",
    "test_csr  = sparse.hstack((test_csr , cntv_user[900000:])).tocsr()\n",
    "\n",
    "train_csr = sparse.hstack((train_csr, tfv_user[:900000])).tocsr()\n",
    "test_csr  = sparse.hstack((test_csr , tfv_user[900000:])).tocsr()\n",
    "\n",
    "train_csr = sparse.hstack((train_csr, cntv_user_ad[:900000])).tocsr()\n",
    "test_csr  = sparse.hstack((test_csr , cntv_user_ad[900000:])).tocsr()\n",
    "\n",
    "train_csr = sparse.hstack((train_csr, tfv_user_ad[:900000])).tocsr()\n",
    "test_csr  = sparse.hstack((test_csr , tfv_user_ad[900000:])).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testuser=pd.read_csv(\"./raw_data/train_semi_final/user.csv\")[-1000000:]\n",
    "testuser['age']=testuser['age']-1\n",
    "testuser['gender']=testuser['gender']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunnyu/.conda/envs/sunnyu/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/sunnyu/.conda/envs/sunnyu/lib/python3.7/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 502.235898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2743259\n",
      "[LightGBM] [Info] Number of data points in the train set: 900000, number of used features: 325608\n",
      "[LightGBM] [Info] Start training from score -3.241491\n",
      "[LightGBM] [Info] Start training from score -1.796631\n",
      "[LightGBM] [Info] Start training from score -1.489637\n",
      "[LightGBM] [Info] Start training from score -1.787914\n",
      "[LightGBM] [Info] Start training from score -1.929743\n",
      "[LightGBM] [Info] Start training from score -2.180171\n",
      "[LightGBM] [Info] Start training from score -2.602025\n",
      "[LightGBM] [Info] Start training from score -3.337691\n",
      "[LightGBM] [Info] Start training from score -3.833315\n",
      "[LightGBM] [Info] Start training from score -4.359352\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttrain's multi_error: 0.564277\teval's multi_error: 0.596383\n",
      "[20]\ttrain's multi_error: 0.537363\teval's multi_error: 0.584892\n",
      "[30]\ttrain's multi_error: 0.51332\teval's multi_error: 0.575958\n"
     ]
    }
   ],
   "source": [
    "tar='age'\n",
    "params = {\n",
    "    'num_leaves':2**8,\n",
    "    'n_estimators':10000,\n",
    "    'early_stopping_rounds':50,\n",
    "#     'max_bin':2**10,\n",
    "    'lambda_l1':1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',    \n",
    "    'num_class':10,\n",
    "    'metric':'multi_error',\n",
    "    'num_threads':20\n",
    "}\n",
    "\n",
    "train_set = lgb.Dataset(train_csr,train_df[tar])\n",
    "val_set=lgb.Dataset(test_csr, testuser[tar])\n",
    "\n",
    "model1 = lgb.train(params,\n",
    "                  train_set,\n",
    "                  valid_sets=[val_set,train_set],\n",
    "                  valid_names=['eval','train'],\n",
    "                  verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'train': {'multi_error': 0.27578},\n",
       "             'eval': {'multi_error': 0.548374}})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar='gender'\n",
    "\n",
    "params = {\n",
    "    'num_leaves':2**7-1,\n",
    "    'n_estimators':10000,\n",
    "    'early_stopping_rounds':50,\n",
    "    'lambda_l1':1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric':'binary_error',\n",
    "    'num_threads':20\n",
    "}\n",
    "\n",
    "train_set = lgb.Dataset(train_csr,train_df[tar])\n",
    "val_set=lgb.Dataset(test_csr, testuser[tar])\n",
    "\n",
    "model2 = lgb.train(params,\n",
    "                  train_set,\n",
    "                  valid_sets=[val_set,train_set],\n",
    "                  valid_names=['eval','train'],\n",
    "                  verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'train': {'binary_error': 0.04469888888888889},\n",
       "             'eval': {'binary_error': 0.067795}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<900000x437652 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 145440000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000000x437652 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 161564576 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame([model1.feature_name(),model1.feature_importance()])\n",
    "importance2 = pd.DataFrame([model2.feature_name(),model2.feature_importance()])\n",
    "importance.T.sort_values(1)[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "genclf=[\n",
    "    LogisticRegression(penalty='l1'),\n",
    "    SGDClassifier(),    \n",
    "    BernoulliNB()\n",
    "]\n",
    "\n",
    "ageclf=[\n",
    "    LogisticRegression(penalty='l1'),\n",
    "    SGDClassifier(),\n",
    "    MultinomialNB()\n",
    "]\n",
    "acc={}\n",
    "\n",
    "for aclf,clf in zip(ageclf,genclf):\n",
    "    aclf.fit(train_csr,train_df['age'])\n",
    "    test_result_age=pd.DataFrame(aclf.predict_proba(test_csr),\n",
    "                                 columns=[aclf.__class__.__name__+'_age_{}'.format(i) for i in range(10)])\n",
    "    test_df=pd.concat([test_df,test_result_age],axis=1)\n",
    "    train_result_age=pd.DataFrame(aclf.predict_proba(train_csr),\n",
    "                                  columns=[aclf.__class__.__name__+'_age_{}'.format(i) for i in range(10)])\n",
    "    train_df=pd.concat([train_df,train_result_age],axis=1)\n",
    "    clf.fit(train_csr,train_df['gender'])\n",
    "    test_result_gen=pd.DataFrame(clf.predict_proba(test_csr),\n",
    "                                 columns=[clf.__class__.__name__+'_gender_{}'.format(i) for i in range(2)])\n",
    "    test_df=pd.concat([test_df,test_result_gen],axis=1)\n",
    "    train_result_gen=pd.DataFrame(clf.predict_proba(train_csr),\n",
    "                                  columns=[clf.__class__.__name__+'_gender_{}'.format(i) for i in range(2)])\n",
    "    train_df=pd.concat([train_df,train_result_gen],axis=1)\n",
    "    test_result_agenp=aclf.predict(test_csr)\n",
    "    test_result_gennp=clf.predict(test_csr)\n",
    "    acc[clf.__class__.__name__]=[accuracy_score(testuser['gender'],test_result_gennp),accuracy_score(testuser['age'],test_result_agenp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc={}\n",
    "from sklearn.metrics import accuracy_score\n",
    "prob=test_df.iloc[:,-12:].values+test_df.iloc[:,-24:-12].values+test_df.iloc[:,-36:-24].values\n",
    "test_result_gennp=pd.DataFrame(prob[:,-2:]).idxmax(1)\n",
    "test_result_agenp=pd.DataFrame(prob[:,:10]).idxmax(1)\n",
    "acc['sum']=[accuracy_score(testuser['gender'],test_result_gennp),accuracy_score(testuser['age'],test_result_agenp)]\n",
    "\n",
    "prob=test_df.iloc[:,-12:].values\n",
    "test_result_gennp=pd.DataFrame(prob[:,-2:]).idxmax(1)\n",
    "test_result_agenp=pd.DataFrame(prob[:,:10]).idxmax(1)\n",
    "acc['NB']=[accuracy_score(testuser['gender'],test_result_gennp),accuracy_score(testuser['age'],test_result_agenp)]\n",
    "prob=test_df.iloc[:,-24:-12].values\n",
    "test_result_gennp=pd.DataFrame(prob[:,-2:]).idxmax(1)\n",
    "test_result_agenp=pd.DataFrame(prob[:,:10]).idxmax(1)\n",
    "acc['SGD']=[accuracy_score(testuser['gender'],test_result_gennp),accuracy_score(testuser['age'],test_result_agenp)]\n",
    "prob=test_df.iloc[:,-36:-24].values\n",
    "test_result_gennp=pd.DataFrame(prob[:,-2:]).idxmax(1)\n",
    "test_result_agenp=pd.DataFrame(prob[:,:10]).idxmax(1)\n",
    "acc['LR_l1']=[accuracy_score(testuser['gender'],test_result_gennp),accuracy_score(testuser['age'],test_result_agenp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sum': [0.919099, 0.399813],\n",
       " 'NB': [0.90695, 0.377696],\n",
       " 'SGD': [0.910405, 0.328027],\n",
       " 'LR_l1': [0.917684, 0.388937]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_pickle('./tmp_data/train_df_tf.pkl')\n",
    "# test_df.to_pickle('./tmp_data/test_df_tf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunnyu/.conda/envs/sunnyu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sunnyu/.conda/envs/sunnyu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogisticRegression': [0.918158, 0.400817]}\n",
      "{'LogisticRegression': [0.918158, 0.400817], 'SGDClassifier': [0.917283, 0.381357]}\n",
      "{'LogisticRegression': [0.918158, 0.400817], 'SGDClassifier': [0.917283, 0.381357], 'BernoulliNB': [0.897853, 0.381901]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "genclf=[\n",
    "    LogisticRegression(penalty='l1'),\n",
    "    SGDClassifier(),    \n",
    "    BernoulliNB(),\n",
    "    LinearSVC()\n",
    "]\n",
    "\n",
    "ageclf=[\n",
    "    LogisticRegression(penalty='l1'),\n",
    "    SGDClassifier(),\n",
    "    MultinomialNB(),\n",
    "    LinearSVC()\n",
    "]\n",
    "acc={}\n",
    "\n",
    "for aclf,clf in zip(ageclf,genclf):\n",
    "    aclf.fit(train_csr,train_df['age'])\n",
    "    clf.fit(train_csr,train_df['gender'])\n",
    "    test_result_agenp=aclf.predict(test_csr)\n",
    "    test_result_gennp=clf.predict(test_csr)\n",
    "    acc[clf.__class__.__name__]=[accuracy_score(testuser['gender'],test_result_gennp),accuracy_score(testuser['age'],test_result_agenp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': [0.918158, 0.400817],\n",
       " 'SGDClassifier': [0.917283, 0.381357],\n",
       " 'BernoulliNB': [0.897853, 0.381901],\n",
       " 'LinearSVC': [0.893187, 0.342516]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
